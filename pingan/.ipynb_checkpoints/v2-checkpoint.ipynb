{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from math import sqrt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train = r\"E:\\\\PINGAN\\\\PINGAN-2018-test_demo1.csv\"\n",
    "path_test = r\"E:\\\\PINGAN\\\\PINGAN-2018-test_demo1.csv\"\n",
    "\n",
    "all_feature_list = ['CALLSTATE', 'DIRECTION', 'HEIGHT', 'LATITUDE', 'LONGITUDE', 'SPEED',\n",
    "       'TERMINALNO', 'TIME', 'TRIP_ID', 'Y', 'time', 'date', 'hour', 'minute',\n",
    "       'trip_max', 'lon_max', 'lon_min', 'lon', 'lat_max', 'lat_min', 'lat',\n",
    "       'heg_max', 'heg_min', 'heg_mean', 'heg', 'vol', 'sp_max', 'sp_mean',\n",
    "       'call0', 'call1', 'call_ratio_0', 'call_ratio_1','dis']\n",
    "\n",
    "use_feature_list = [\n",
    "       'trip_max', 'lon_max', 'lon_min', 'lon', 'lat_max', 'lat_min', 'lat',\n",
    "       'heg_max', 'heg_min', 'heg_mean', 'heg', 'vol', 'sp_max', 'sp_mean',\n",
    "       'call_ratio_0', 'call_ratio_1', 'dis', 'ave_dri_time', 'dri_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path_train,path_test):\n",
    "    train_data = pd.read_csv(path_train)\n",
    "    test_data = pd.read_csv(path_test)\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载数据\n",
    "train_data,test_data=load_data(path_train,path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#拼接训练集和测试集进行特征工程\n",
    "test_data['TERMINALNO'] = test_data['TERMINALNO']+train_data['TERMINALNO'].max()\n",
    "data = pd.concat([train_data,test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#重置index\n",
    "data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#时间处理\n",
    "def time_datetime(value):\n",
    "    format = '%Y%m%d%H%M'\n",
    "    value = time.localtime(value)\n",
    "    dt = time.strftime(format, value)\n",
    "    return int(dt)\n",
    "\n",
    "def time_date(value):\n",
    "    format = '%Y%m%d'\n",
    "    value = time.localtime(value)\n",
    "    dt = time.strftime(format, value)\n",
    "    return int(dt)\n",
    "\n",
    "def time_hour(value):\n",
    "    format = '%H'\n",
    "    value = time.localtime(value)\n",
    "    dt = time.strftime(format, value)\n",
    "    return int(dt)\n",
    "def time_minute(value):\n",
    "    format = '%M'\n",
    "    value = time.localtime(value)\n",
    "    dt = time.strftime(format, value)\n",
    "    return int(dt)\n",
    "\n",
    "#转换成时刻\n",
    "data['time']=data['TIME'].apply(time_datetime)\n",
    "data['date']=data['TIME'].apply(time_date)\n",
    "data['hour']=data['TIME'].apply(time_hour)\n",
    "data['minute']=data['TIME'].apply(time_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trip_max\n",
    "feature=pd.DataFrame()\n",
    "feature[['TERMINALNO','trip_max']]=pd.DataFrame(data['TRIP_ID'].groupby(data['TERMINALNO']).max()).reset_index()[['TERMINALNO','TRIP_ID']]\n",
    "\n",
    "# lon_max lon_min lon\n",
    "lonmax=pd.DataFrame()\n",
    "lonmin=pd.DataFrame()\n",
    "lonmax[['TERMINALNO','lon_max']]=pd.DataFrame(data['LONGITUDE'].groupby(data['TERMINALNO']).max()).reset_index()[['TERMINALNO','LONGITUDE']]\n",
    "lonmin[['TERMINALNO','lon_min']]=pd.DataFrame(data['LONGITUDE'].groupby(data['TERMINALNO']).min()).reset_index()[['TERMINALNO','LONGITUDE']]\n",
    "feature=pd.merge(feature,lonmax,how='left',on='TERMINALNO')\n",
    "feature=pd.merge(feature,lonmin,how='left',on='TERMINALNO')\n",
    "feature['lon']=feature['lon_max']-feature['lon_min']\n",
    "\n",
    "# lat_max lat_min lat\n",
    "latmax=pd.DataFrame()\n",
    "latmin=pd.DataFrame()\n",
    "latmax[['TERMINALNO','lat_max']]=pd.DataFrame(data['LATITUDE'].groupby(data['TERMINALNO']).max()).reset_index()[['TERMINALNO','LATITUDE']]\n",
    "latmin[['TERMINALNO','lat_min']]=pd.DataFrame(data['LATITUDE'].groupby(data['TERMINALNO']).min()).reset_index()[['TERMINALNO','LATITUDE']]\n",
    "feature=pd.merge(feature,latmax,how='left',on='TERMINALNO')\n",
    "feature=pd.merge(feature,latmin,how='left',on='TERMINALNO')\n",
    "feature['lat']=feature['lat_max']-feature['lat_min']\n",
    "\n",
    "# heg_max heg_min heg_mean heg\n",
    "hegmax=pd.DataFrame()\n",
    "hegmin=pd.DataFrame()\n",
    "hegmean=pd.DataFrame()\n",
    "hegmax[['TERMINALNO','heg_max']]=pd.DataFrame(data['HEIGHT'].groupby(data['TERMINALNO']).max()).reset_index()[['TERMINALNO','HEIGHT']]\n",
    "hegmin[['TERMINALNO','heg_min']]=pd.DataFrame(data['HEIGHT'].groupby(data['TERMINALNO']).min()).reset_index()[['TERMINALNO','HEIGHT']]\n",
    "hegmean[['TERMINALNO','heg_mean']]=pd.DataFrame(data['HEIGHT'].groupby(data['TERMINALNO']).mean()).reset_index()[['TERMINALNO','HEIGHT']]\n",
    "feature=pd.merge(feature,hegmax,how='left',on='TERMINALNO')\n",
    "feature=pd.merge(feature,hegmin,how='left',on='TERMINALNO')\n",
    "feature=pd.merge(feature,hegmean,how='left',on='TERMINALNO')\n",
    "feature['heg']=feature['heg_max']-feature['heg_min']\n",
    "\n",
    "# volu 活动区间体积\n",
    "feature['vol']=feature['lon']*feature['lat']*feature['heg']\n",
    "\n",
    "# 速度 sp_max sp_mean\n",
    "spmax=pd.DataFrame()\n",
    "spmean=pd.DataFrame()\n",
    "spmax[['TERMINALNO','sp_max']]=pd.DataFrame(data['SPEED'].groupby(data['TERMINALNO']).max()).reset_index()[['TERMINALNO','SPEED']]\n",
    "spmean[['TERMINALNO','sp_mean']]=pd.DataFrame(data['SPEED'].groupby(data['TERMINALNO']).mean()).reset_index()[['TERMINALNO','SPEED']]\n",
    "feature=pd.merge(feature,spmax,how='left',on='TERMINALNO')\n",
    "feature=pd.merge(feature,spmean,how='left',on='TERMINALNO')\n",
    "\n",
    "#callstate\n",
    "call0=pd.DataFrame()\n",
    "call1=pd.DataFrame()\n",
    "call0[['TERMINALNO','call0']]=pd.DataFrame(data['CALLSTATE'][data['CALLSTATE'] == 0].groupby(data['TERMINALNO']).count()).reset_index()[['TERMINALNO','CALLSTATE']]\n",
    "call1[['TERMINALNO','call1']]=pd.DataFrame(data['CALLSTATE'][data['CALLSTATE'] > 0].groupby(data['TERMINALNO']).count()).reset_index()[['TERMINALNO','CALLSTATE']]\n",
    "feature=pd.merge(feature,call0,how='left',on='TERMINALNO')\n",
    "feature=pd.merge(feature,call1,how='left',on='TERMINALNO')\n",
    "\n",
    "feature['call0'].fillna(0,inplace=True)\n",
    "feature['call1'].fillna(0,inplace=True)\n",
    "feature['call_ratio_0']=feature['call0']/(feature['call0']+feature['call1'])\n",
    "feature['call_ratio_1']=feature['call1']/(feature['call0']+feature['call1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "# 行程\n",
    "# 对每个USER 按 TIME 排序\n",
    "sortdata = data.sort_values(['TERMINALNO','time']).reset_index(drop = True)\n",
    "# 删除TRIP_ID后去重\n",
    "del sortdata['TRIP_ID']\n",
    "sortdata.drop_duplicates(inplace=True)\n",
    "# 计算经纬度差\n",
    "sortdata['difflat'] = sortdata.groupby(['TERMINALNO'])['LATITUDE'].diff()\n",
    "sortdata['difflon'] = sortdata.groupby(['TERMINALNO'])['LONGITUDE'].diff()\n",
    "# 对每个用户的第一个经纬度差置0\n",
    "sortdata.fillna(0.0,inplace=True)\n",
    "# 计算单个距离\n",
    "sortdata['dis2'] = sortdata['difflat'] ** 2 + sortdata['difflon'] ** 2\n",
    "sortdata['dis'] = sortdata['dis2'].apply(sqrt)\n",
    "del sortdata['dis2']\n",
    "# 计算总行程\n",
    "# disdata = pd.DataFrame()\n",
    "# disdata[['TERMINALNO','dis']]=sortdata['dis'].groupby(['TERMINALNO']).sum()\n",
    "disdata = sortdata['dis'].groupby(sortdata['TERMINALNO']).sum().reset_index()\n",
    "feature = pd.merge(feature,disdata,how='left',on='TERMINALNO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 驾驶时长 \n",
    "# 1.去重\n",
    "dri_time = data[['TERMINALNO','TIME','TRIP_ID']]\n",
    "dri_time.drop_duplicates(subset=['TERMINALNO','TIME'],inplace=True)\n",
    "# 2.按 TERMINALNO 和 time 排序\n",
    "dri_time.sort_values(['TERMINALNO','TIME'],inplace=True)\n",
    "dri_time['diff_time']=dri_time.groupby(['TERMINALNO'])['TIME'].diff()\n",
    "dri_time.fillna(0.0,inplace=True)\n",
    "# 3.时间换算\n",
    "dri_time['diff_time'] = dri_time['diff_time'].apply(lambda x: x / 60)\n",
    "# 4.如果时间间隔大于20分钟则按新行程处理，置0\n",
    "def f(x):\n",
    "    if x >= 20:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "dri_time['diff_time'] = dri_time['diff_time'].apply(f)\n",
    "# 5.计算驾驶总时长\n",
    "dri_t = pd.DataFrame()\n",
    "dri_t[['TERMINALNO','dri_time']] = dri_time['diff_time'].groupby(dri_time['TERMINALNO']).sum().reset_index()[['TERMINALNO','diff_time']]\n",
    "feature = pd.merge(feature,dri_t,how='left',on='TERMINALNO')\n",
    "# 6.平均时长\n",
    "feature['ave_dri_time'] = feature['dri_time'] / feature['trip_max'] \n",
    "# 7.用户单段最大驾驶时长\n",
    "del dri_t,dri_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.sort_values(by=['TIME'], inplace=True)\n",
    "# data['diff_time'] = data.groupby(['TERMINALNO', 'TRIP_ID'])['TIME'].diff()\n",
    "# value = {'diff_time': 0}\n",
    "# data.fillna(value=value, inplace=True)\n",
    "# dri_time = pd.DataFrame()\n",
    "# dri_time[['TERMINALNO', 'dri_time']] = pd.DataFrame(data.groupby(['TERMINALNO'])['diff_time'].sum()).reset_index()\n",
    "# dri_time['dri_time'] = dri_time['dri_time'].apply(lambda x: x / 60)\n",
    "# feature = pd.merge(feature, dri_time, how='left', on='TERMINALNO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 归一化\n",
    "feature['trip_max'] = feature['trip_max'].apply(\n",
    "    lambda x: (x - feature['trip_max'].min()) / (feature['trip_max'].max() - feature['trip_max'].min()))\n",
    "feature['lon_max'] = feature['lon_max'].apply(\n",
    "    lambda x: (x - feature['lon_max'].min()) / (feature['lon_max'].max() - feature['lon_max'].min()))\n",
    "feature['lon_min'] = feature['lon_min'].apply(\n",
    "    lambda x: (x - feature['lon_min'].min()) / (feature['lon_min'].max() - feature['lon_min'].min()))\n",
    "feature['lon'] = feature['lon'].apply(\n",
    "    lambda x: (x - feature['lon'].min()) / (feature['lon'].max() - feature['lon'].min()))\n",
    "feature['lat_min'] = feature['lat_min'].apply(\n",
    "    lambda x: (x - feature['lat_min'].min()) / (feature['lat_min'].max() - feature['lat_min'].min()))\n",
    "feature['lat_max'] = feature['lat_max'].apply(\n",
    "    lambda x: (x - feature['lat_max'].min()) / (feature['lat_max'].max() - feature['lat_max'].min()))\n",
    "feature['lat'] = feature['lat'].apply(\n",
    "    lambda x: (x - feature['lat'].min()) / (feature['lat'].max() - feature['lat'].min()))\n",
    "feature['heg_min'] = feature['heg_min'].apply(\n",
    "    lambda x: (x - feature['heg_min'].min()) / (feature['heg_min'].max() - feature['heg_min'].min()))\n",
    "feature['heg_max'] = feature['heg_max'].apply(\n",
    "    lambda x: (x - feature['heg_max'].min()) / (feature['heg_max'].max() - feature['heg_max'].min()))\n",
    "feature['heg'] = feature['heg'].apply(\n",
    "    lambda x: (x - feature['heg'].min()) / (feature['heg'].max() - feature['heg'].min()))\n",
    "feature['heg_mean'] = feature['heg_mean'].apply(\n",
    "    lambda x: (x - feature['heg_mean'].min()) / (feature['heg_mean'].max() - feature['heg_mean'].min()))\n",
    "feature['vol'] = feature['vol'].apply(\n",
    "    lambda x: (x - feature['vol'].min()) / (feature['vol'].max() - feature['vol'].min()))\n",
    "feature['sp_max'] = feature['sp_max'].apply(\n",
    "    lambda x: (x - feature['sp_max'].min()) / (feature['sp_max'].max() - feature['sp_max'].min()))\n",
    "feature['sp_mean'] = feature['sp_mean'].apply(\n",
    "    lambda x: (x - feature['sp_mean'].min()) / (feature['sp_mean'].max() - feature['sp_mean'].min()))\n",
    "feature['ave_dri_time'] = feature['ave_dri_time'].apply(\n",
    "    lambda x: (x - feature['ave_dri_time'].min()) / (feature['ave_dri_time'].max() - feature['ave_dri_time'].min()))\n",
    "feature['dri_time'] = feature['dri_time'].apply(\n",
    "    lambda x: (x - feature['dri_time'].min()) / (feature['dri_time'].max() - feature['dri_time'].min()))\n",
    "feature['dis'] = feature['dis'].apply(\n",
    "    lambda x: (x - feature['dis'].min()) / (feature['dis'].max() - feature['dis'].min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_train_shape:(55444, 35)  train_val_shape:(13862, 35)\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "b'Unknown parameter: random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-41567730ef9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mlgbmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBMRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_leaves\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m63\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m lgbmodel.fit(X=train_train[use_feature_list], y=train_train['Y'],\n\u001b[1;32m---> 21\u001b[1;33m              eval_set=(train_val[use_feature_list], train_val['Y']), early_stopping_rounds=200,verbose=False)\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mfea_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_feature_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\anaconda\\envs\\python35\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    487\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\anaconda\\envs\\python35\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    389\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\anaconda\\envs\\python35\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, callbacks)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;34m\"\"\"construct booster\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\anaconda\\envs\\python35\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[0;32m   1209\u001b[0m             \u001b[1;34m\"\"\"construct booster object\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[1;32m-> 1211\u001b[1;33m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[1;32md:\\develop\\anaconda\\envs\\python35\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    805\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[0;32m    808\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\anaconda\\envs\\python35\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, max_bin, reference, weight, group, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\anaconda\\envs\\python35\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[1;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init_from_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\anaconda\\envs\\python35\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: b'Unknown parameter: random_state'"
     ]
    }
   ],
   "source": [
    "# 切割训练集和测试集\n",
    "train = data[0:len(train_data)]\n",
    "test = data[len(train_data):]\n",
    "train = pd.merge(train, feature, how='left', on='TERMINALNO')\n",
    "test = pd.merge(test, feature, how='left', on='TERMINALNO')\n",
    "train['Y'] = train['Y'].apply(lambda x: ((x-train['Y'].min())/(train['Y'].max()-train['Y'].min())))\n",
    "# 训练集和验证集划分\n",
    "train_train, train_val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "print(\"train_train_shape:\"+str(train_train.shape)+\"  train_val_shape:\"+str(train_val.shape))\n",
    "\n",
    "# train_train['Y'] = train_train['Y'].apply(\n",
    "#     lambda x: ((x - train_train['Y'].min())/(train_train['Y'].max()-train_train['Y'].min()))\n",
    "# )\n",
    "# train_val['Y'] = train_val['Y'].apply(\n",
    "#     lambda x: ((x - train_val['Y'].min()) / (train_val['Y'].max() - train_val['Y'].min()))\n",
    "# )\n",
    "\n",
    "#模型训练\n",
    "lgbmodel = lgb.LGBMRegressor(num_leaves=63, max_depth=7, n_estimators=20000,learning_rate=0.0001)\n",
    "lgbmodel.fit(X=train_train[use_feature_list], y=train_train['Y'],\n",
    "             eval_set=(train_val[use_feature_list], train_val['Y']), early_stopping_rounds=200,verbose=False)\n",
    "\n",
    "fea_imp = pd.Series(lgbmodel.feature_importances_,use_feature_list).sort_values(ascending=False)\n",
    "print(fea_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
